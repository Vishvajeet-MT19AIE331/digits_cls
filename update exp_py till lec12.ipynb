{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ce3d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________________________________\n",
      "TRAINING LOGS:\n",
      "The combination of tested parameters for SVM are:\n",
      "[{'gamma': 0.0001, 'C': 0.1}, {'gamma': 0.0005, 'C': 0.1}, {'gamma': 0.001, 'C': 0.1}, {'gamma': 0.01, 'C': 0.1}, {'gamma': 0.1, 'C': 0.1}, {'gamma': 1, 'C': 0.1}, {'gamma': 0.0001, 'C': 1}, {'gamma': 0.0005, 'C': 1}, {'gamma': 0.001, 'C': 1}, {'gamma': 0.01, 'C': 1}, {'gamma': 0.1, 'C': 1}, {'gamma': 1, 'C': 1}, {'gamma': 0.0001, 'C': 10}, {'gamma': 0.0005, 'C': 10}, {'gamma': 0.001, 'C': 10}, {'gamma': 0.01, 'C': 10}, {'gamma': 0.1, 'C': 10}, {'gamma': 1, 'C': 10}, {'gamma': 0.0001, 'C': 100}, {'gamma': 0.0005, 'C': 100}, {'gamma': 0.001, 'C': 100}, {'gamma': 0.01, 'C': 100}, {'gamma': 0.1, 'C': 100}, {'gamma': 1, 'C': 100}, {'gamma': 0.0001, 'C': 1000}, {'gamma': 0.0005, 'C': 1000}, {'gamma': 0.001, 'C': 1000}, {'gamma': 0.01, 'C': 1000}, {'gamma': 0.1, 'C': 1000}, {'gamma': 1, 'C': 1000}]\n",
      "The combination of tested parameters for Decision Tree are:\n",
      "[{'max_depth': 5}, {'max_depth': 10}, {'max_depth': 15}, {'max_depth': 20}, {'max_depth': 50}, {'max_depth': 100}]\n",
      "____________________________________________________________________________________________________________________________\n",
      "train+dev = 1437 test = 360\n",
      "BEST RESULTS:\n",
      "svm\ttest_size=0.20 dev_size=0.20 train_size=0.60 train_acc=1.00 dev_acc=0.99 test_acc=0.99, test_f1=0.99\n",
      "Best model: ./models/svm_gamma_0.001_C_1.joblib\n",
      "BEST RESULTS:\n",
      "tree\ttest_size=0.20 dev_size=0.20 train_size=0.60 train_acc=1.00 dev_acc=0.88 test_acc=0.81, test_f1=0.81\n",
      "Best model: ./models/tree_max_depth_100.joblib\n",
      "____________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Program for selecting the best performing models and training and saving them ###########\n",
    "\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import metrics, svm\n",
    "\n",
    "from utils import preprocess_data, split_data, train_model, read_digits, predict_and_eval, train_test_dev_split, get_hyperparameter_combinations, tune_hparams\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "\n",
    "num_runs  = 1\n",
    "# 1. Get the dataset\n",
    "X, y = read_digits()\n",
    "\n",
    "# 2. Hyperparameter combinations\n",
    "classifier_param_dict = {}\n",
    "# 2.1. SVM\n",
    "gamma_list = [0.0001, 0.0005, 0.001, 0.01, 0.1, 1]\n",
    "C_list = [0.1, 1, 10, 100, 1000]\n",
    "h_params={}\n",
    "h_params['gamma'] = gamma_list\n",
    "h_params['C'] = C_list\n",
    "h_params_combinations = get_hyperparameter_combinations(h_params)\n",
    "classifier_param_dict['svm'] = h_params_combinations\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "print('TRAINING LOGS:')\n",
    "print('The combination of tested parameters for SVM are:')\n",
    "print(h_params_combinations)\n",
    "\n",
    "# 2.2 Decision Tree\n",
    "max_depth_list = [5, 10, 15, 20, 50, 100]\n",
    "h_params_tree = {}\n",
    "h_params_tree['max_depth'] = max_depth_list\n",
    "h_params_trees_combinations = get_hyperparameter_combinations(h_params_tree)\n",
    "classifier_param_dict['tree'] = h_params_trees_combinations\n",
    "print()\n",
    "print('The combination of tested parameters for Decision Tree are:')\n",
    "print(h_params_trees_combinations)\n",
    "print('____________________________________________________________________________________________________________________________')\n",
    "\n",
    "\n",
    "results = []\n",
    "test_sizes =  [0.2]\n",
    "dev_sizes  =  [0.2]\n",
    "for cur_run_i in range(num_runs):\n",
    "    \n",
    "    for test_size in test_sizes:\n",
    "        for dev_size in dev_sizes:\n",
    "            train_size = 1- test_size - dev_size\n",
    "            # 3. Data splitting -- to create train and test sets                \n",
    "            X_train, X_test, X_dev, y_train, y_test, y_dev = train_test_dev_split(X, y, test_size=test_size, dev_size=dev_size)\n",
    "            # 4. Data preprocessing\n",
    "            X_train = preprocess_data(X_train)\n",
    "            X_test = preprocess_data(X_test)\n",
    "            X_dev = preprocess_data(X_dev)\n",
    "\n",
    "            binary_preds = {}\n",
    "            model_preds = {}\n",
    "            for model_type in classifier_param_dict:\n",
    "                current_hparams = classifier_param_dict[model_type]\n",
    "                best_hparams, best_model_path, best_accuracy  = tune_hparams(X_train, y_train, X_dev, \n",
    "                y_dev, current_hparams, model_type)        \n",
    "            \n",
    "                # loading of model         \n",
    "                best_model = load(best_model_path) \n",
    "\n",
    "                test_acc, test_f1, predicted_y = predict_and_eval(best_model, X_test, y_test)\n",
    "                train_acc, train_f1, _ = predict_and_eval(best_model, X_train, y_train)\n",
    "                dev_acc = best_accuracy\n",
    "                \n",
    "                print('BEST RESULTS:')\n",
    "                print(\"{}\\ttest_size={:.2f} dev_size={:.2f} train_size={:.2f} train_acc={:.2f} dev_acc={:.2f} test_acc={:.2f}, test_f1={:.2f}\".format(model_type, test_size, dev_size, train_size, train_acc, dev_acc, test_acc, test_f1))\n",
    "                print('Best model:',best_model_path)\n",
    "                cur_run_results = {'model_type': model_type, 'run_index': cur_run_i, 'train_acc' : train_acc, 'dev_acc': dev_acc, 'test_acc': test_acc}\n",
    "                results.append(cur_run_results)\n",
    "                binary_preds[model_type] = y_test == predicted_y\n",
    "                model_preds[model_type] = predicted_y\n",
    "                \n",
    "                #print(\"{}-GroundTruth Confusion metrics\".format(model_type))\n",
    "                #print(metrics.confusion_matrix(y_test, predicted_y))\n",
    "\n",
    "\n",
    "#print(\"svm-tree Confusion metrics\".format())\n",
    "#print(metrics.confusion_matrix(model_preds['svm'], model_preds['tree']))\n",
    "\n",
    "#print(\"binarized predictions\")\n",
    "#print(metrics.confusion_matrix(binary_preds['svm'], binary_preds['tree'], labels=[True, False]))\n",
    "#print(\"binarized predictions -- normalized over true labels\")\n",
    "#print(metrics.confusion_matrix(binary_preds['svm'], binary_preds['tree'], labels=[True, False] , normalize='true'))\n",
    "#print(\"binarized predictions -- normalized over pred  labels\")\n",
    "#print(metrics.confusion_matrix(binary_preds['svm'], binary_preds['tree'], labels=[True, False] , normalize='pred'))\n",
    "        \n",
    "# print(pd.DataFrame(results).groupby('model_type').describe().T)\n",
    "print('____________________________________________________________________________________________________________________________')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
